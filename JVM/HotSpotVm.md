## About Hot_Spot VM And OSR ( On Stack Replacement )

### HotSpot VM 이야기
```text
HotSpot VM은 기본적으로 JIT 컴파일러를 두 개 내장하고 있다.
하나는 컴파일 속도가 빠른 대신 최적화를 적게 하는 클라이언트 컴파일러(C1 컴파일러)
다른 하나는 컴파일 속도는 느리지만 더 많은 최적화를 적용하는 서버 컴파일러(C2 컴파일러)
여기에 인터프리터까지 포함하여 총 3개의 실행 메커니즘이 협력하여 HotSpot VM의 실행 서브시스템을 구성한다.

JDK 10부터는 Graal컴파일러까지 추가되었다. 앞서 말한 서버 컴파일러(C2 컴파일러)를 대체할 목적으로 핫스팟에 도입되었다.
그랄 컴파일러는 부분 탈출 분석(partial escape analysis)처럼 C2보다 복잡한 최적화도 수행할 수 있다.
또한 맞춤형 가정 등을 추가해 공격적 예측 최적화(aggressive speculative optimization)를 적용하기에도 더 수월하다.

JDK 10 ~ 15 에서 그랄 컴파일러를 사용해보고 싶다면 
 +UnlockExperimentalVMOptions -XX:+UseJVMCI-Compiler 
매개 변수를 지정하면 된다.

JDK 16부터는 개발과 관리 효율을 높이고자 그랄 컴파일러를 JDK에서 독립시켜 그랄VM으로 터전을 옮겼다.
```


### JIT (Just In Time) 컴파일러
```text
"컴파일 했을 때 효과를 가장 크게 볼 수 있는 코드" 영역을 런타임에 알아내어 JIT 컴파일러에 알려준다. 
그러면 JIT 컴파일러가 해당 코드를 메서드 단위로 컴파일한다. 
메서드가 자주 호출되거나 메서드 안에 시간을 많이 잡아 먹는 순환문이 있다면 JIT 컴파일을 수행해 스택을 치환하는 것이다. 
이처럼 런타임에 스택을 치환하는 기술을 OSR 이라고 한다.
컴파일 없이 즉시 실행한 다음, 일부 코드만 백그라운드에서 컴파일 하여 치환하는 방식이다.

- JVM 밑바닥까지 파헤치기 中 -
```

### 1. "컴파일 했을 때 효과를 가장 크게 볼 수 있는 코드"(= hot spot)를 어떻게 찾는가
- 핫스팟이란
  - 자주 호출되거나
  - 오래 실행되거나(루프가 매우 길거나, 루프가 반복을 많이 돌거나)

- 런타임 시스템 (JVM, JS Engine 등)은 다음과 같은 방식으로 핫스팟을 찾는다.
1. 모든 메서드/루프에 대해 counter를 둔다.
   - 메서드 진입 횟수 카운팅
   - 특정 루프(back edge)를 몇 번 돌았는지 루프 카운팅
2. 인터프리터가 코드를 실행할 때마다 이 카운터가 동작
3. 카운터가 특정 임계값(threshold)을 넘으면
    - 이 코드는 자주 실행되는구나 -> 컴파일하면 이득이 크겠다 라고 판단
    - JIT 컴파일러에게 "이 메서드/루프를 최적화해라"라고 요청 (compile request)

- 즉, "런타임에 알아내어 JIT 컴파일러에 알려준다"는 문장은
  - 실행 중에 통계를 계속 모으고
  - 자주 실행되는 코드만 선별해서 JIT에게 넘긴다
  <br/> 라는 의미

### 2. "메서드가 자주 호출되거나 메서드 안에 시간을 많이 잡아 먹는 순환문이 있다면 JIT 컴파일을 수행해 ```스택을 치환하는 것이다.```"
- 여기서 핵심 고려사항은 두 가지
  - 언제 JIT를 돌릴지 -> 핫스팟 찾기
  - 어떻게 기존 실행을 끊지 않고 최적화된 코드로 교체할지 -> 스택 치환 (OSR)

- ```스택을 치환한다```는 문장은 이미 인터프리터로 실행 중인 ```해당 함수/루프```의 현재 호출 프레임을,
  - "인터프리터 버전의 스택 프레임"에서
  - "컴파일된 코드 버전의 스택 프레임"으로
  <br/> 런타임 중간에 그대로 교체한다는 의미

### 3. OSR (On-Stack Replacement)이 필요한 이유
1. JIT는 핫스팟을 찾기 위해 ```충분히 많이 실행될 때까지``` 기다린다.
2. 하지만 어떤 코드는 ```이미 굉장히 많은 횟수를 반복 중인 루프```한가운데에서 핫스팟으로 판명된다.
3. 그 순간부터 ```앞으로 수십만 번을 더 순회할```여지가 있는데, 그냥 인터프리터로 계속 실행시에는 너무 느리다.
4. ```다음에 이 메서드/루프가 처음부터 다시 호출될 때부터만```컴파일된 버전을 쓴다면, 이미 실행중에 있는 이 코드는 끝까지 인터프리터 실행으로 돈다.
5. 그래서 OSR을 쓰면 ```이미 굉장히 많은 횟수를 반복 중인 루프```한가운데에서 핫스팟으로 판명된다면
6. 그 시점에 JIT 컴파일러가 ```루프 중간 지점에서 바로 진입 가능한 버젼```을 컴파일하고
7. 인터프리터로 실행되던 현재 스택프레임을 ```컴파일된 코드의 스택 레이아웃```으로 변환한 뒤
8. 그 다음 반복부터는 컴파일된 네이티브 코드가 실행을 이어가는 방식으로 동작


## 더 알아보기

### 💥 1. What is Instantaneous execution by Interpreter
- ```바이트코드를 하나씩 읽어서, 그 바이트코드에 대응하는 기계어 시퀀스를 직접 실행하는 것```
- ```즉, 즉석 변환이 아니라 미리 만든 기계어 루틴을 호출하는 구조```
- 인터프리터의 실제 동작 (HotSpot JVM 인터프리터[= template interpreter] 기준)
1. 바이트코드 하나 읽기
2. 그 바이트코드를 처리하는 미리 구현된 C++ 함수/기계어 코드 실행
```C
switch (bytecode) {
    case: IADD:
        excute precompiled iadd_handler();
    case: INVOKEVIRTUAL:
        excute invokevirtual_handler();    
}
```

### 💥 2. miss_understanding & truth of JVM
- 헷갈리고 있던 이유는 대부분 아래 두 이미지가 상충되기 때문..
1. 자바는 바이트코드를 네이티브 코드로 변환해서 실행 (컴파일 -> 실행)

- ❌오해 : 자바 바이트코드는 JVM이 곧바로 네이티브 코드로 변환해서 실행한다.
- ✔️ 사실 
  - 시작 시점은 인터프리터 실행
  - 실행 통계를 보고 핫스팟으로 감지된 코드는 JIT 컴파일러가 네이티브 코드로 컴파일
  - OSR이 개입하여 이미 실행 중인 함수/루프의 스택프레임을 네이티브 코드로 교체
  - 결과적으로 ```네이티브 코드로 실행되는 것처럼 빠른 속도```를 얻는다.

### 💥 3. MSA 환경에서의 Java 어플리케이션 이야기
```text
  어플리케이션 아키텍처의 중심은 MSA로 옮겨지고 있지만 자바는 이 추세와 잘 맞지 않는다.
  MSA에서는 분할된 서비스 각각이 더 이상 수십에서 수백GB의 메모리를 쓸 일이 없다.
  고가용성 서비스 클러스터를 활용하면 단일 서비스를 24시간 중단 없이 실행하기 위해 노력할 이유가 줄어든다.
  언제든지 중단하고 업데이트 할 수 있기 때문이다. 하지만 자바는 구동 시간이 길고 최고 성능을 내기까지 예열이 필요하다.
  마이크로서비스가 요구하는 특성과는 반대인 것이다.
  게다가 서버리스 아키텍처에서는 이러한 모순이 더욱 두드러진다. 함수는 서비스보다도 크기가 작고 실행시간이 짧다.
  현재 가장 널리 쓰이는 서버리스 런타임인 AWS람다는 함수 실행 시간을 최장 15분까지만 허용한다.
  
  이런 흐름에 맞추어 애플리케이션 실행 전에 네이티브 코드로 컴파일 해두는 AOT(Ahead Of Time) 컴파일 방식이 있다.
  지금까지 자바 가상 머신은 어플리케이션을 우선 실행한 후 JIT 컴파일러를 써서 빈번하게 실행되는 로직을 네이티브 코드로 바꾸어 실행했다.
  하지만 AOT 컴파일 방식으로 이러한 예열 과정을 건너뛰고 처음부터 네이티브 코드를 실행할 수 있다.
  다만 "한번 작성하면 어디서든 실행된다"라는 자바의 약속을 지킬 수 없다. 
  다시 말해 하드웨어와 운영 체제별로 따로 컴파일해 배포해두어야 한다. 
  또한 자바의 동적 링크 특성이 크게 줄어든다. 
  컴파일할 코드에 대한 모든 것을 컴파일타임에 알 수 있어야 한다. 
```
